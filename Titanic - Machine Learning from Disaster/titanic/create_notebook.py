#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Jupyter Notebookãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
import nbformat as nbf

def create_simple_notebook():
    """ã‚·ãƒ³ãƒ—ãƒ«ãªCSVãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
    
    # æ–°ã—ã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆ
    nb = nbf.v4.new_notebook()
    
    # ã‚»ãƒ«ã‚’è¿½åŠ 
    cells = []
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã‚»ãƒ«
    title_cell = nbf.v4.new_markdown_cell("""# ğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼

Titanicãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç°¡å˜ã«è¡¨ç¤ºã—ã¾ã™ã€‚""")
    cells.append(title_cell)
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    import_cell = nbf.v4.new_code_cell("""import pandas as pd
import numpy as np

print("âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†")""")
    cells.append(import_cell)
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    train_section = nbf.v4.new_markdown_cell("""## 1. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ (train.csv)""")
    cells.append(train_section)
    
    train_load = nbf.v4.new_code_cell("""# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
train_df = pd.read_csv('Titanic - Machine Learning from Disaster/titanic/train.csv')

print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {train_df.shape[0]}è¡Œ Ã— {train_df.shape[1]}åˆ—")
print(f"ğŸ“‹ åˆ—å: {list(train_df.columns)}")
print("\\n" + "="*80)

# æœ€åˆã®10è¡Œã‚’è¡¨ç¤º
train_df.head(10)""")
    cells.append(train_load)
    
    train_stats = nbf.v4.new_code_cell("""# åŸºæœ¬çµ±è¨ˆæƒ…å ±
print("ğŸ“ˆ åŸºæœ¬çµ±è¨ˆæƒ…å ±")
print("="*30)
train_df.describe()""")
    cells.append(train_stats)
    
    train_missing = nbf.v4.new_code_cell("""# æ¬ æå€¤ã®ç¢ºèª
missing = train_df.isnull().sum()
print("âš ï¸ æ¬ æå€¤ã®ç¢ºèª")
print("="*30)
for col, count in missing.items():
    if count > 0:
        percentage = (count / len(train_df)) * 100
        print(f"{col}: {count}ä»¶ ({percentage:.1f}%)")
    else:
        print(f"{col}: æ¬ æãªã—")""")
    cells.append(train_missing)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    test_section = nbf.v4.new_markdown_cell("""## 2. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ (test.csv)""")
    cells.append(test_section)
    
    test_load = nbf.v4.new_code_cell("""# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
test_df = pd.read_csv('Titanic - Machine Learning from Disaster/titanic/test.csv')

print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {test_df.shape[0]}è¡Œ Ã— {test_df.shape[1]}åˆ—")
print(f"ğŸ“‹ åˆ—å: {list(test_df.columns)}")
print("\\n" + "="*80)

# æœ€åˆã®10è¡Œã‚’è¡¨ç¤º
test_df.head(10)""")
    cells.append(test_load)
    
    test_missing = nbf.v4.new_code_cell("""# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¬ æå€¤
missing_test = test_df.isnull().sum()
print("âš ï¸ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¬ æå€¤")
print("="*30)
for col, count in missing_test.items():
    if count > 0:
        percentage = (count / len(test_df)) * 100
        print(f"{col}: {count}ä»¶ ({percentage:.1f}%)")
    else:
        print(f"{col}: æ¬ æãªã—")""")
    cells.append(test_missing)
    
    # ã‚µãƒ³ãƒ—ãƒ«æå‡ºã‚»ã‚¯ã‚·ãƒ§ãƒ³
    submission_section = nbf.v4.new_markdown_cell("""## 3. ã‚µãƒ³ãƒ—ãƒ«æå‡ºãƒ•ã‚¡ã‚¤ãƒ« (gender_submission.csv)""")
    cells.append(submission_section)
    
    submission_load = nbf.v4.new_code_cell("""# ã‚µãƒ³ãƒ—ãƒ«æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
gender_submission = pd.read_csv('Titanic - Machine Learning from Disaster/titanic/gender_submission.csv')

print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {gender_submission.shape[0]}è¡Œ Ã— {gender_submission.shape[1]}åˆ—")
print(f"ğŸ“‹ åˆ—å: {list(gender_submission.columns)}")
print("\\n" + "="*80)

# æœ€åˆã®10è¡Œã‚’è¡¨ç¤º
gender_submission.head(10)""")
    cells.append(submission_load)
    
    submission_stats = nbf.v4.new_code_cell("""# ã‚µãƒ³ãƒ—ãƒ«æå‡ºã®çµ±è¨ˆ
print("ğŸ“ˆ ã‚µãƒ³ãƒ—ãƒ«æå‡ºã®çµ±è¨ˆ")
print("="*30)
print(f"ç”Ÿå­˜äºˆæ¸¬: {gender_submission['Survived'].sum()}äºº")
print(f"æ­»äº¡äºˆæ¸¬: {(gender_submission['Survived'] == 0).sum()}äºº")
print(f"ç”Ÿå­˜ç‡äºˆæ¸¬: {gender_submission['Survived'].mean():.3f} ({gender_submission['Survived'].mean()*100:.1f}%)")""")
    cells.append(submission_stats)
    
    # æ¯”è¼ƒã‚»ã‚¯ã‚·ãƒ§ãƒ³
    compare_section = nbf.v4.new_markdown_cell("""## 4. ãƒ‡ãƒ¼ã‚¿ã®æ¯”è¼ƒ""")
    cells.append(compare_section)
    
    compare_cell = nbf.v4.new_code_cell("""print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¯”è¼ƒ")
print("="*50)
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_df.shape[0]}è¡Œ Ã— {train_df.shape[1]}åˆ—")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_df.shape[0]}è¡Œ Ã— {test_df.shape[1]}åˆ—")
print(f"ã‚µãƒ³ãƒ—ãƒ«æå‡º: {gender_submission.shape[0]}è¡Œ Ã— {gender_submission.shape[1]}åˆ—")

print("\\nğŸ” ä¸»ãªé•ã„:")
print("â€¢ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ã¯ 'Survived' åˆ—ãŒã‚ã‚‹ï¼ˆæ•™å¸«ãƒ‡ãƒ¼ã‚¿ï¼‰")
print("â€¢ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã¯ 'Survived' åˆ—ãŒãªã„ï¼ˆäºˆæ¸¬å¯¾è±¡ï¼‰")
print("â€¢ ã‚µãƒ³ãƒ—ãƒ«æå‡ºã¯æ€§åˆ¥ãƒ™ãƒ¼ã‚¹ã®ç°¡å˜ãªäºˆæ¸¬ä¾‹")""")
    cells.append(compare_cell)
    
    # ã‚»ãƒ«ã‚’ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«è¿½åŠ 
    nb.cells = cells
    
    # ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä¿å­˜
    with open('simple_csv_viewer.ipynb', 'w', encoding='utf-8') as f:
        nbf.write(nb, f)
    
    print("âœ… simple_csv_viewer.ipynb ã‚’ä½œæˆã—ã¾ã—ãŸ")

def create_analysis_notebook():
    """è©³ç´°åˆ†æç”¨ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆ"""
    
    # æ–°ã—ã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆ
    nb = nbf.v4.new_notebook()
    
    # ã‚»ãƒ«ã‚’è¿½åŠ 
    cells = []
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã‚»ãƒ«
    title_cell = nbf.v4.new_markdown_cell("""# ğŸš¢ Titanicãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†æ

ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Titanicã®ä¹—å®¢ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ã€ç”Ÿå­˜äºˆæ¸¬ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã‚’è¡Œã„ã¾ã™ã€‚""")
    cells.append(title_cell)
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    import_cell = nbf.v4.new_code_cell("""import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.style.use('seaborn-v0_8')

print("âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†")""")
    cells.append(import_cell)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data_section = nbf.v4.new_markdown_cell("""## 2. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿""")
    cells.append(data_section)
    
    data_load = nbf.v4.new_code_cell("""# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
train_df = pd.read_csv('Titanic - Machine Learning from Disaster/titanic/train.csv')
test_df = pd.read_csv('Titanic - Machine Learning from Disaster/titanic/test.csv')
gender_submission = pd.read_csv('Titanic - Machine Learning from Disaster/titanic/gender_submission.csv')

print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_df.shape}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_df.shape}")
print(f"ã‚µãƒ³ãƒ—ãƒ«æå‡º: {gender_submission.shape}")""")
    cells.append(data_load)
    
    # åŸºæœ¬æƒ…å ±
    info_section = nbf.v4.new_markdown_cell("""## 3. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±""")
    cells.append(info_section)
    
    info_cell = nbf.v4.new_code_cell("""print("ğŸ” è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±")
print("="*50)
train_df.info()""")
    cells.append(info_cell)
    
    head_cell = nbf.v4.new_code_cell("""print("ğŸ“‹ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®5è¡Œ")
print("="*50)
train_df.head()""")
    cells.append(head_cell)
    
    describe_cell = nbf.v4.new_code_cell("""print("ğŸ“Š æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±")
print("="*50)
train_df.describe()""")
    cells.append(describe_cell)
    
    # æ¬ æå€¤
    missing_section = nbf.v4.new_markdown_cell("""## 4. æ¬ æå€¤ã®ç¢ºèª""")
    cells.append(missing_section)
    
    missing_cell = nbf.v4.new_code_cell("""# æ¬ æå€¤ã®ç¢ºèª
missing_train = train_df.isnull().sum()
missing_test = test_df.isnull().sum()

print("âš ï¸ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ¬ æå€¤")
print("="*30)
for col, count in missing_train.items():
    if count > 0:
        percentage = (count / len(train_df)) * 100
        print(f"{col}: {count}ä»¶ ({percentage:.1f}%)")

print("\\nâš ï¸ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¬ æå€¤")
print("="*30)
for col, count in missing_test.items():
    if count > 0:
        percentage = (count / len(test_df)) * 100
        print(f"{col}: {count}ä»¶ ({percentage:.1f}%)")""")
    cells.append(missing_cell)
    
    # ç”Ÿå­˜ç‡åˆ†æ
    survival_section = nbf.v4.new_markdown_cell("""## 5. ç”Ÿå­˜ç‡ã®åˆ†æ""")
    cells.append(survival_section)
    
    survival_cell = nbf.v4.new_code_cell("""# å…¨ä½“ã®ç”Ÿå­˜ç‡
survival_rate = train_df['Survived'].mean()
print(f"ğŸ“ˆ å…¨ä½“ã®ç”Ÿå­˜ç‡: {survival_rate:.3f} ({survival_rate*100:.1f}%)")

# æ€§åˆ¥åˆ¥ã®ç”Ÿå­˜ç‡
gender_survival = train_df.groupby('Sex')['Survived'].agg(['count', 'sum', 'mean'])
gender_survival.columns = ['ç·æ•°', 'ç”Ÿå­˜è€…æ•°', 'ç”Ÿå­˜ç‡']
print("\\nğŸ‘¥ æ€§åˆ¥åˆ¥ã®ç”Ÿå­˜ç‡")
print("="*30)
print(gender_survival)""")
    cells.append(survival_cell)
    
    # ã‚»ãƒ«ã‚’ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«è¿½åŠ 
    nb.cells = cells
    
    # ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä¿å­˜
    with open('titanic_analysis.ipynb', 'w', encoding='utf-8') as f:
        nbf.write(nb, f)
    
    print("âœ… titanic_analysis.ipynb ã‚’ä½œæˆã—ã¾ã—ãŸ")

if __name__ == "__main__":
    print("ğŸ“ Jupyter Notebookãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...")
    create_simple_notebook()
    create_analysis_notebook()
    print("ğŸ‰ å®Œäº†ã—ã¾ã—ãŸï¼") 