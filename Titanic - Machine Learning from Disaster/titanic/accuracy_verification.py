#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç²¾åº¦ã®æ¤œè¨¼ã¨ç­”ãˆåˆã‚ã›
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

def preprocess_data(df, is_training=True):
    """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’è¡Œã†é–¢æ•°"""
    
    # ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
    df_processed = df.copy()
    
    # 1. å¹´é½¢ã®æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§è£œå®Œ
    df_processed['Age'].fillna(df_processed['Age'].median(), inplace=True)
    
    # 2. é‹è³ƒã®æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§è£œå®Œï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
    if 'Fare' in df_processed.columns:
        df_processed['Fare'].fillna(df_processed['Fare'].median(), inplace=True)
    
    # 3. ä¹—èˆ¹æ¸¯ã®æ¬ æå€¤ã‚’æœ€é »å€¤ã§è£œå®Œ
    df_processed['Embarked'].fillna(df_processed['Embarked'].mode()[0], inplace=True)
    
    # 4. å®¢å®¤ç•ªå·ã®æ¬ æå€¤ã‚’å‡¦ç†ï¼ˆæ¬ æã®å ´åˆã¯0ã€ãã†ã§ãªã‘ã‚Œã°1ï¼‰
    df_processed['HasCabin'] = df_processed['Cabin'].notna().astype(int)
    
    # 5. å®¶æ—ã‚µã‚¤ã‚ºã®è¨ˆç®—
    df_processed['FamilySize'] = df_processed['SibSp'] + df_processed['Parch'] + 1
    
    # 6. ä¸€äººæ—…ã‹ã©ã†ã‹ã®åˆ¤å®š
    df_processed['IsAlone'] = (df_processed['FamilySize'] == 1).astype(int)
    
    # 7. å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ
    df_processed['AgeGroup'] = pd.cut(df_processed['Age'], 
                                      bins=[0, 12, 18, 30, 50, 100], 
                                      labels=[0, 1, 2, 3, 4])
    
    # 8. é‹è³ƒã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ
    df_processed['FareGroup'] = pd.qcut(df_processed['Fare'], 
                                       q=4, 
                                       labels=[0, 1, 2, 3], 
                                       duplicates='drop')
    
    # 9. æ€§åˆ¥ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    df_processed['Sex_encoded'] = (df_processed['Sex'] == 'female').astype(int)
    
    # 10. ä¹—èˆ¹æ¸¯ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    embarked_mapping = {'S': 0, 'C': 1, 'Q': 2}
    df_processed['Embarked_encoded'] = df_processed['Embarked'].map(embarked_mapping)
    
    # ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã‚’é¸æŠ
    features = ['Pclass', 'Sex_encoded', 'Age', 'SibSp', 'Parch', 'Fare', 
                'Embarked_encoded', 'HasCabin', 'FamilySize', 'IsAlone', 
                'AgeGroup', 'FareGroup']
    
    # æ¬ æå€¤ã‚’å«ã‚€åˆ—ã‚’é™¤å¤–
    available_features = [f for f in features if f in df_processed.columns]
    
    if is_training:
        return df_processed[available_features], df_processed['Survived']
    else:
        return df_processed[available_features]

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    print("ğŸ” ç²¾åº¦ã®æ¤œè¨¼ã¨ç­”ãˆåˆã‚ã›")
    print("="*50)
    
    # 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    train_df = pd.read_csv('Titanic - Machine Learning from Disaster/titanic/train.csv')
    
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_df.shape}")
    
    # 2. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
    print("\nğŸ”§ ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ä¸­...")
    X_train, y_train = preprocess_data(train_df, is_training=True)
    
    print(f"å‰å‡¦ç†å¾Œã®ç‰¹å¾´é‡: {X_train.shape}")
    
    # 3. ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ï¼ˆæ¤œè¨¼ç”¨ï¼‰
    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ä¸­...")
    X_train_split, X_val, y_train_split, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )
    
    print(f"è¨“ç·´ã‚»ãƒƒãƒˆ: {X_train_split.shape}")
    print(f"æ¤œè¨¼ã‚»ãƒƒãƒˆ: {X_val.shape}")
    
    # 4. ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    print("\nğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
    model = GradientBoostingClassifier(n_estimators=100, random_state=42)
    model.fit(X_train_split, y_train_split)
    
    # 5. æ¤œè¨¼ã‚»ãƒƒãƒˆã§äºˆæ¸¬
    print("\nğŸ”® æ¤œè¨¼ã‚»ãƒƒãƒˆã§äºˆæ¸¬ä¸­...")
    y_pred = model.predict(X_val)
    
    # 6. ç²¾åº¦ã®è¨ˆç®—
    accuracy = accuracy_score(y_val, y_pred)
    print(f"ç²¾åº¦: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # 7. è©³ç´°ãªåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
    print("\nğŸ“‹ è©³ç´°ãªåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
    print("="*30)
    print(classification_report(y_val, y_pred, target_names=['æ­»äº¡', 'ç”Ÿå­˜']))
    
    # 8. æ··åŒè¡Œåˆ—
    print("\nğŸ“Š æ··åŒè¡Œåˆ—:")
    print("="*30)
    cm = confusion_matrix(y_val, y_pred)
    print("äºˆæ¸¬\\å®Ÿéš›    æ­»äº¡  ç”Ÿå­˜")
    print("æ­»äº¡        {:4d}  {:4d}".format(cm[0,0], cm[0,1]))
    print("ç”Ÿå­˜        {:4d}  {:4d}".format(cm[1,0], cm[1,1]))
    
    # 9. å…·ä½“çš„ãªç­”ãˆåˆã‚ã›ä¾‹
    print("\nğŸ” å…·ä½“çš„ãªç­”ãˆåˆã‚ã›ä¾‹ï¼ˆæ¤œè¨¼ã‚»ãƒƒãƒˆã‹ã‚‰10ä»¶ï¼‰:")
    print("="*50)
    
    # æ¤œè¨¼ã‚»ãƒƒãƒˆã®å…ƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    val_indices = train_df.index[train_test_split(
        range(len(train_df)), train_df['Survived'], 
        test_size=0.2, random_state=42, stratify=train_df['Survived']
    )[1]]
    
    val_data = train_df.iloc[val_indices].copy()
    val_data['Predicted'] = y_pred
    val_data['Actual'] = y_val.values
    val_data['Correct'] = (val_data['Predicted'] == val_data['Actual'])
    
    # æ­£è§£ã¨ä¸æ­£è§£ã®ä¾‹ã‚’è¡¨ç¤º
    print("\nâœ… æ­£è§£ã—ãŸäºˆæ¸¬ã®ä¾‹:")
    correct_examples = val_data[val_data['Correct'] == True].head(5)
    for _, row in correct_examples.iterrows():
        sex_jp = 'å¥³æ€§' if row['Sex'] == 'female' else 'ç”·æ€§'
        embarked_jp = {'S': 'ã‚µã‚¦ã‚µãƒ³ãƒ—ãƒˆãƒ³', 'C': 'ã‚·ã‚§ãƒ«ãƒ–ãƒ¼ãƒ«', 'Q': 'ã‚¯ã‚¤ãƒ¼ãƒ³ã‚ºã‚¿ã‚¦ãƒ³'}[row['Embarked']]
        result = 'ç”Ÿå­˜' if row['Actual'] == 1 else 'æ­»äº¡'
        print(f"  {row['Name']} ({sex_jp}, {row['Age']}æ­³, {row['Pclass']}ç­‰å®¢å®¤) â†’ {result} (æ­£è§£)")
    
    print("\nâŒ é–“é•ã£ãŸäºˆæ¸¬ã®ä¾‹:")
    incorrect_examples = val_data[val_data['Correct'] == False].head(5)
    for _, row in incorrect_examples.iterrows():
        sex_jp = 'å¥³æ€§' if row['Sex'] == 'female' else 'ç”·æ€§'
        embarked_jp = {'S': 'ã‚µã‚¦ã‚µãƒ³ãƒ—ãƒˆãƒ³', 'C': 'ã‚·ã‚§ãƒ«ãƒ–ãƒ¼ãƒ«', 'Q': 'ã‚¯ã‚¤ãƒ¼ãƒ³ã‚ºã‚¿ã‚¦ãƒ³'}[row['Embarked']]
        predicted = 'ç”Ÿå­˜' if row['Predicted'] == 1 else 'æ­»äº¡'
        actual = 'ç”Ÿå­˜' if row['Actual'] == 1 else 'æ­»äº¡'
        print(f"  {row['Name']} ({sex_jp}, {row['Age']}æ­³, {row['Pclass']}ç­‰å®¢å®¤) â†’ äºˆæ¸¬:{predicted}, å®Ÿéš›:{actual}")
    
    # 10. æ€§åˆ¥åˆ¥ã®ç²¾åº¦
    print("\nğŸ‘¥ æ€§åˆ¥åˆ¥ã®ç²¾åº¦:")
    print("="*30)
    val_data_with_sex = val_data.copy()
    val_data_with_sex['Sex_encoded'] = (val_data_with_sex['Sex'] == 'female').astype(int)
    
    for sex, sex_name in [(0, 'ç”·æ€§'), (1, 'å¥³æ€§')]:
        sex_data = val_data_with_sex[val_data_with_sex['Sex_encoded'] == sex]
        if len(sex_data) > 0:
            sex_accuracy = sex_data['Correct'].mean()
            print(f"{sex_name}: {sex_accuracy:.4f} ({sex_accuracy*100:.2f}%) - {len(sex_data)}ä»¶")
    
    # 11. å®¢å®¤ã‚¯ãƒ©ã‚¹åˆ¥ã®ç²¾åº¦
    print("\nğŸ« å®¢å®¤ã‚¯ãƒ©ã‚¹åˆ¥ã®ç²¾åº¦:")
    print("="*30)
    for pclass in [1, 2, 3]:
        class_data = val_data[val_data['Pclass'] == pclass]
        if len(class_data) > 0:
            class_accuracy = class_data['Correct'].mean()
            print(f"{pclass}ç­‰å®¢å®¤: {class_accuracy:.4f} ({class_accuracy*100:.2f}%) - {len(class_data)}ä»¶")
    
    print("\nğŸ‰ æ¤œè¨¼å®Œäº†ï¼")

if __name__ == "__main__":
    main() 