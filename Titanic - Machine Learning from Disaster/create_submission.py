#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Titanicç”Ÿå­˜äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« - æå‡ºç”¨CSVä½œæˆ
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
import warnings
warnings.filterwarnings('ignore')

def preprocess_data(df, is_training=True):
    """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’è¡Œã†é–¢æ•°"""
    
    # ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
    df_processed = df.copy()
    
    # 1. å¹´é½¢ã®æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§è£œå®Œ
    df_processed['Age'].fillna(df_processed['Age'].median(), inplace=True)
    
    # 2. é‹è³ƒã®æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§è£œå®Œï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
    if 'Fare' in df_processed.columns:
        df_processed['Fare'].fillna(df_processed['Fare'].median(), inplace=True)
    
    # 3. ä¹—èˆ¹æ¸¯ã®æ¬ æå€¤ã‚’æœ€é »å€¤ã§è£œå®Œ
    df_processed['Embarked'].fillna(df_processed['Embarked'].mode()[0], inplace=True)
    
    # 4. å®¢å®¤ç•ªå·ã®æ¬ æå€¤ã‚’å‡¦ç†ï¼ˆæ¬ æã®å ´åˆã¯0ã€ãã†ã§ãªã‘ã‚Œã°1ï¼‰
    df_processed['HasCabin'] = df_processed['Cabin'].notna().astype(int)
    
    # 5. å®¶æ—ã‚µã‚¤ã‚ºã®è¨ˆç®—
    df_processed['FamilySize'] = df_processed['SibSp'] + df_processed['Parch'] + 1
    
    # 6. ä¸€äººæ—…ã‹ã©ã†ã‹ã®åˆ¤å®š
    df_processed['IsAlone'] = (df_processed['FamilySize'] == 1).astype(int)
    
    # 7. å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ
    df_processed['AgeGroup'] = pd.cut(df_processed['Age'], 
                                      bins=[0, 12, 18, 30, 50, 100], 
                                      labels=[0, 1, 2, 3, 4])
    
    # 8. é‹è³ƒã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ
    df_processed['FareGroup'] = pd.qcut(df_processed['Fare'], 
                                       q=4, 
                                       labels=[0, 1, 2, 3], 
                                       duplicates='drop')
    
    # 9. æ€§åˆ¥ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    df_processed['Sex_encoded'] = (df_processed['Sex'] == 'female').astype(int)
    
    # 10. ä¹—èˆ¹æ¸¯ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    embarked_mapping = {'S': 0, 'C': 1, 'Q': 2}
    df_processed['Embarked_encoded'] = df_processed['Embarked'].map(embarked_mapping)
    
    # ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã‚’é¸æŠ
    features = ['Pclass', 'Sex_encoded', 'Age', 'SibSp', 'Parch', 'Fare', 
                'Embarked_encoded', 'HasCabin', 'FamilySize', 'IsAlone', 
                'AgeGroup', 'FareGroup']
    
    # æ¬ æå€¤ã‚’å«ã‚€åˆ—ã‚’é™¤å¤–
    available_features = [f for f in features if f in df_processed.columns]
    
    if is_training:
        return df_processed[available_features], df_processed['Survived']
    else:
        return df_processed[available_features]

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    print("ğŸš¢ Titanicç”Ÿå­˜äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« - æå‡ºç”¨CSVä½œæˆ")
    print("="*50)
    
    # 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    train_df = pd.read_csv('Titanic - Machine Learning from Disaster/titanic/train.csv')
    test_df = pd.read_csv('Titanic - Machine Learning from Disaster/titanic/test.csv')
    
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train_df.shape}")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_df.shape}")
    
    # 2. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
    print("\nğŸ”§ ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ä¸­...")
    X_train, y_train = preprocess_data(train_df, is_training=True)
    X_test = preprocess_data(test_df, is_training=False)
    
    print(f"å‰å‡¦ç†å¾Œã®ç‰¹å¾´é‡: {X_train.shape}")
    
    # 3. ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    print("\nğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
    model = GradientBoostingClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # 4. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
    print("\nğŸ”® ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ä¸­...")
    predictions = model.predict(X_test)
    
    print(f"äºˆæ¸¬å®Œäº†: {len(predictions)}ä»¶")
    print(f"ç”Ÿå­˜äºˆæ¸¬: {predictions.sum()}äºº")
    print(f"æ­»äº¡äºˆæ¸¬: {(predictions == 0).sum()}äºº")
    print(f"ç”Ÿå­˜ç‡äºˆæ¸¬: {predictions.mean():.3f} ({predictions.mean()*100:.1f}%)")
    
    # 5. æå‡ºç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
    print("\nğŸ’¾ æå‡ºç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...")
    
    # PassengerIdã¨Survivedã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    submission_df = pd.DataFrame({
        'PassengerId': test_df['PassengerId'],
        'Survived': predictions
    })
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    submission_df.to_csv('titanic_submission.csv', index=False)
    
    print("âœ… titanic_submission.csv ã‚’ä½œæˆã—ã¾ã—ãŸ")
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {submission_df.shape}")
    
    # 6. çµæœã®ç¢ºèª
    print("\nğŸ“‹ æå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€åˆã®10è¡Œ:")
    print(submission_df.head(10))
    
    print("\nğŸ“Š äºˆæ¸¬çµæœã®æ¦‚è¦:")
    print(f"ç·ä¹—å®¢æ•°: {len(submission_df)}äºº")
    print(f"ç”Ÿå­˜äºˆæ¸¬: {submission_df['Survived'].sum()}äºº")
    print(f"æ­»äº¡äºˆæ¸¬: {(submission_df['Survived'] == 0).sum()}äºº")
    print(f"ç”Ÿå­˜ç‡: {submission_df['Survived'].mean():.3f} ({submission_df['Survived'].mean()*100:.1f}%)")
    
    print("\nğŸ‰ å®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main() 